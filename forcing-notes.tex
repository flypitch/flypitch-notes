\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry} 
\usepackage{tikz-cd}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsmath,amsthm,amssymb,mathrsfs,mathabx}
\usepackage{enumitem}
\usepackage{csquotes}
\usepackage{color} 
\usepackage{parskip}
\usepackage{hyperref}
\usepackage{fixltx2e}
\usepackage{tcolorbox}
\usepackage{jmhmacros}

\newcommand{\arity}{\opn{arity}}
\graphicspath{ {/home/pv/Pictures/latex/} }

\begin{document}

\title{Forcing and the independence of the continuum hypothesis}
\author{Jesse Han}
\date{\today}

\maketitle


\begin{abstract}
In these notes, intended as the plaintext part of the Flypitch project, we give a complete account of the independence of the continuum hypothesis from $\msf{ZFC}$, with special attention paid to comparing the different approaches: generic sets, Boolean-valued models, and double-negation sheaves.
\end{abstract}

% TODO(jesse) \section*{Introduction}

\section{Preliminaries}

\subsection{First-order logic}
\subsubsection{General logical symbols}
\definition{\label{def-general-logical-symbol} We reserve the following general logical symbols:
$$  \begin{gmatrix}
   \neg & \te{not}\\
 \lor   & \te{or}\\
 \land   & \te{and}\\
  \forall  & \te{for all}\\
  \exists & \te{exists}\\
  = & \te{equals}\\
  (,) & \te{parentheses} \\
  (x_i)_{i : \N}, (y_i)_{i : \N}, (z_i)_{i : \N} & \te{variables}
\end{gmatrix}$$
}

\subsubsection{First-order languages}
\definition{\label{def-language} A (first-order, one-sorted) \tbf{language} $\mc{L}$ comprises the following data:
  \bfenumerate{
  \item A collection of \tbf{constant symbols} $\msf{Const}(\mc{L})$,
  \item a collection of \tbf{relation symbols} $\msf{Rel}(\mc{L})$,
  \item a collection of \tbf{function symbols} $\msf{Funct}(\mc{L})$, and
  \item an assignment of each symbol $S : \msf{Const}(\mc{L}) \cup \msf{Rel}(\mc{L}) \cup \msf{Funct}(\mc{L})$ to a natural number $\opn{arity}(S) : \mbb{N}$.
    }
  }

Whenever we interpret a language on some carrier $A$, we mean for constants $c$ to be interpreted as elements of $A^{\opn{arity}(c)}$, relations $R$ to be interpreted as subsets of $A^{\opn{arity}(R)}$, and for function symbols to be interpreted as functions $A^{\opn{arity}(f)} \to A$.
  
  \example{
    \begin{itemize}
    \item The language of groups comprises a $1$-ary constant symbol for the identity and a $2$-ary function for group multiplication.

    \item The language of rings comprises constant symbols $0$ and $1$ and $2$-ary functions for addition and multiplication.

     \item The language of set theory comprises just one $2$-ary relation $\in$.
    \end{itemize}
  }

\subsubsection{Terms, formulas, and sentences}
\definition{\label{def-term} A \tbf{term} is a string of symbols defined by structural induction as follows:
  \begin{enumerate}
  \item Any variable $v$ is a term.
  \item Any constant $c$ is a term.
  \item If $t_1, \dots, t_n$ are terms of arities $a_1, \dots, a_n$, then $(t_1, \dots, t_n)$ is a term of arity $a_1 + \dots + a_n$.
  \item If $t$ is a term and $f$ is a function symbol with matching arities, then $f t$ is a term.
  \end{enumerate}
}

Whenever we interpret our language on a carrier $A$, we mean for terms to be interpreted as functions into $A$ which we can construct by composing existing constants (constant functions), basic functions (i.e. the interpretations of the function symbols), and variables (identity).

\definition{\label{def-formula} A \tbf{formula} is defined by structural induction as follows:
  \begin{enumerate}
  \item If $t_1$ and $t_2$ are terms of the same arity, $t_1 = t_2$ is a formula.
  \item If $t$ is a term and $R$ is a relation symbol, and $t$ and $R$ have the same arity, then $R t$ is a formula.
  \item If $\varphi$ is a formula, $\neg \varphi$ is a formula.
  \item If $\varphi$ and $\psi$ are formulas, then $\varphi \lor \psi$ is a formula.
  \item If $\varphi$ and $\psi$ are formulas, then $\varphi \land \psi$ is a formula.
  \item If $\varphi$ is a formula containing a variable $v$, then $\exists v \varphi$ is a formula.
  \item If $\varphi$ is a formula containing a variable $v$, then $\forall v \varphi v$ is a formula.
  \end{enumerate}
}

\definition{\label{def-free-variable}
  Let $\varphi$ be a formula containing the variables $x_1, \dots, x_n$. We say that the variable $x_k$ is \tbf{free} if $x_k$ is not contained in a subformula of the form $\exists x_k \psi$ or $\forall x_k \psi$.

  $x_k$ is \tbf{bound} if it is not free.
}

\definition{\label{def-sentence}
  A formula is a \tbf{sentence} (or \tbf{statement}) if it contains no free variables.

  We write $\msf{Formulas}(\mc{L})$ for all the first-order formulas of $\mc{L}$, and we write $\msf{Sentences}(\mc{L})$ for all the first-order sentences of $\mc{L}$.
}

By convention, we always include sentences called $\true$ and $\false$.


\subsubsection{Predicate calculus and provability}
Throughout this section, we fix a language $\mc{L}$.
% \definition{
%   \label{def-propositional-function}
%   Fix an $n > 1$. The collection of functions $\{\false, \true\}^n \to \{\false, \true\}$ inherits the structure of a Boolean algebra by performing operations pointwise.

%   A \tbf{propositional function} $\{\false, \true\}^n \to \{\false, \true\}$ is defined inductively as follows:
%   \begin{enumerate}
%   \item Every projection $(\epsilon_1, \dots, \epsilon_n) \mapsto \epsilon_k$ is a propositional function.
%   \item If $P$ and $Q$ are propositional functions, then so are
%     $$
% \neg P, P \land Q, P \lor Q, P \to Q, \te{ and } P \leftrightarrow Q.
%     $$
%   \end{enumerate}

% A propositional function is a \tbf{tautology} if it is constantly true.
% }

\definition{
  \label{def-tautology}
  \label{def-propositional-function}
  A \tbf{propositional function} is a function $f : \msf{Prop}^k \to \msf{Prop}$, for some $1 < k : \N$ which we define inductively as follows:
  \begin{enumerate}
  \item The constant functions to $\true$ and $\false$ are propositional functions.
  \item Each projection $(P_1, \dots, P_k) \mapsto P_j$ is a propositional function.
  \item If $f$ and $g$ are propositional functions, so are
    $$
\neg f, f \land g, f \lor g, f \rightarrow g, \te{ and } f \leftrightarrow g,
$$
where the operations above are carried out pointwise in $\msf{Prop}$.
  \end{enumerate}
$f$ is a \tbf{tautology} if $\vdash \forall \vec{p} : \msf{Prop}^k, f \vec{p} \leftrightarrow \true$.
}

\definition{
  \label{def-propositional-combination}
  A \tbf{propositional combination} is a function $f : \msf{Sentences}(\mc{L})^k \to \msf{Sentences}(\mc{L})^k$, for some $1 < k : \N$ which we define inductively as follows:
  \begin{enumerate}
  \item Each projection $(B_1, \dots, B_k) \mapsto B_j$ is a propositional combination.
  \item If $f$ and $g$ are propositional combinations, so are
    $$\neg f, f \land g, f \lor g, f \rightarrow g, \te{ and } f \leftrightarrow g,$$
    where the operations are carried out pointwise in $\msf{Sentences}(\mc{L})$.
  \end{enumerate}
}

By sending projections to projections and symbols $(\neg, \land, \lor, \rightarrow, \leftrightarrow)$ to the corresponding operations on $\msf{Prop}$, every propositional combination $f : \msf{Sentences}(\mc{L})^{k} \to \msf{Sentences}(\mc{L})$ can be realized as a propositional function $\mbf{r}(f) : \msf{Prop}^k \to \msf{Prop}$.

\definition{
  \label{def-predicate-calculus}
  The \tbf{predicate calculus} comprises the following rules for deducing sentences from other sentences. We call deducible sentences \tbf{valid}, and write $\entails_{\mc{L}} \varphi$ to mean that the $\mc{L}$-sentence $\varphi$ is valid (and to disambiguate from $\entails$, which when used unadorned means ``provable in the metatheory).

\alphenumerate{
\item (Rule of the propositional calculus) if $f$ is a propositional combination taking $k$ arguments such that $\mbf{r}(f)$ is a tautology, then for any $k$ sentences $A_1, \dots, A_k$, the value of the propositional combination $f(\varphi_1, \dots, \varphi_k)$ is a valid sentence.

\item (Rule of modus ponens) If $A$ and $A \to B$ are valid, then $B$ is valid.

\item (Rules of equality)
  \bfenumerate{
  \item $\forall x, x = x$, $\forall x \forall y, x = y \wedge y = x$, and $\forall x \forall y \forall z, x = y \wedge y = z \rightarrow x = z$ are all valid.
  \item Let $\varphi(x)$ be a formula whose only free variable is $x$. Then
    $$
\forall x \forall y, (x = y) \rightarrow (\varphi(x) \rightarrow \varphi(y))
$$
is valid.
  }
\item (Change of variable)
  If $A$ is a sentence and $A'$ represents $A$ with all instances of a variable $x$ switched to $y$, then $A \leftrightarrow A'$ is valid.

\item (Rule of specialization ``$\forall$-elimination'')
  Let $c$ be any constant symbol, and let $\varphi(x)$ be a formula whose only free variable is $x$. Then $(\forall x \varphi(x)) \to \varphi(c)$ is valid.
  
\item (``$\neg$-introduction'')
  If $\neg A \leftrightarrow (A \to \false)$ is valid.
  
\item (Generalization of constants ``$\forall$-introduction'') \label{forall-introduction}
  Let $B$ be a sentence which does not contain the constant $c$ or the variable $x$. Let $\varphi(x)$ be some formula such that $\varphi(c) \to B$ is valid. Then $\exists x \varphi(x) \to B$ is also valid.\footnote{In particular, using the next rule, if $\neg \varphi(c) \to \false$ is valid, so is $\exists x \neg \varphi(x) \to \false$, so is $\neg \exists x \neg \varphi(x)$, and therefore so is $\forall x \varphi(x)$.}

\item (de Morgan laws)
  Let $\varphi(x)$ have $x$ as its only free variable. Let $B$ be a sentence which does not contain $x$. Then the following are valid statements:
  $$(\neg (\forall x \varphi(x))) \leftrightarrow (\exists x \neg \varphi(x))$$
  $$((\forall x \varphi(x)) \wedge B ) \leftrightarrow \left((\forall x(\varphi(x) \wedge  B\right)$$
  $$((\exists x \varphi(x)) \wedge B ) \leftrightarrow \left((\exists x(\varphi(x) \wedge B\right)$$
  }
  }

  \definition{\label{def-provable} \label{def-consistent} Let $S$ be a collection of sentences. \bfenumerate{
      \item We say that $A$ is provable from $S$ if there exist finitely many $B_1, \dots, B_n : S$ such that $\left(B_1 \wedge \dots \wedge B_n \right) \to A$ is valid.

      \item  We say that $S$ is consistent if $\false$ is not valid.
      }
    }

    \remark{
One may wonder why we work with a type of formulas and not with a collection of $\Prop$s directly. The problem with this is that everything needs to be typed, and so to reason about a predicate (say ``$\in$'') using $\Prop$, we need some carrier type $A$ such that $\in : A \to A \to \Prop$, so that e.g. $\in$ satisfies the axioms of set theory. But then what does it mean for some other type $B$ to have an interpretation of $\in$ and the axioms it satisfies? There then needs to be a separate predicate $\in_B : B \to B \to \Prop$ satisfying the same \emph{kind} of $\Prop$s as $\in : A \to A \to \Prop$. We could proceed to define a typeclass of such $(B, \in_B)$, and we would then be working with models of set theory, but we would lack a way to reason syntactically about the axioms themselves.
      }
      
  
      \subsection{Models and satisfiability}
      For the remainder of this section we fix a language $\mc{L}$.
\definition{
  \label{def-theory}
 An \tbf{$\mc{L}$-theory} is a collection of sentences from $\msf{Sentences}(\mc{L})$.
}

\definition{
  \label{def-structure}
  An \tbf{$\mc{L}$-structure} comprises the following data:
  \bfenumerate{
  \item A carrier type $A$,
  \item an assignment of every $c : \msf{Const}(\mc{L})$ to a $c^A : A^{\opn{arity}(c)}$,
  \item an assignment of every $R : \msf{Rel}(\mc{L})$ to a subtype $R^A : A^{\opn{arity}(R)} \to \msf{Prop}$,
  \item an assignment of every $f : \msf{Funct}(\mc{L})$ to a function $f^A : A^{\opn{arity}(f)} \to A$.
    }
  }
  \definition{
    \label{def-realization-of-terms}
    Let $A$ be an $\mc{L}$-structure. Using the data of $A$ being an $\mc{L}$-structure, we can inductively assign to every term $t$ (of arity $k$ and containing $n$ free variables) a \tbf{realization} $\mbf{r}(t) : A^n \to A^k$, as follows:
    \begin{enumerate}
    \item If $t = v$ for a variable $v$, $\mbf{r}(t) = \id_A = \lambda v, v$.
    \item If $t = c$ for a constant symbol $c$, $\mbf{r}(t) = A^0 \overset{c^A}{\to} A$.
    \item If $t = (t_1, \dots, t_m)$, then $\mbf{r}(t) = \mbf{r}(t_1) \times \dots \times \mbf{r}(t_m)$.
    \item If $t = f(t_0)$ for some function symbol $f$, then $\mbf{r}(t) = f^A \circ \mbf{r}(t_0)$.
    \end{enumerate}
    }
  
  \definition{
    \label{def-realization-of-formulas}
    Let $A$ be an $\mc{L}$-structure. Using the data of $A$ being an $\mc{L}$-structure, we can inductively assign to every formula $\varphi(x_1, \dots, x_n)$ (where $x_1, \dots, x_n$ exhaust the free variables of $\varphi$) a \tbf{realization} $\mbf{r}(\varphi) : A^n \to \msf{Prop}$, as follows:
    \begin{enumerate}
    \item If $\varphi$ is of the form $t_1 = t_2$, then $\mbf{r}(\varphi)$ is $\mbf{r}(t_1) = \mbf{r}(t_2)$ (where symbolic equality is realized as true equality).

    \item If $\varphi$ is of the form $R(t)$, $\mbf{r}(R(t))$ is $R^A(\mbf{r}(t))$.

    \item If $\varphi$ is of the form $\neg \psi$, then $\mbf{r}(\varphi)$ is $\neg \mbf{r}(\psi)$.

    \item If $\varphi$ is of the form $\psi \lor \psi'$, then $\mbf{r}(\varphi)$ is $\mbf{r}(\psi) \lor \mbf{r}(\psi')$.

    \item If $\varphi$ is of the form $\psi \land \psi'$, then $\mbf{r}(\varphi)$ is $\mbf{r}(\psi) \land \mbf{r}(\psi')$.

    \item If $\varphi$ is of the form $\exists v \psi$, then $\mbf{r}(\varphi)$ is $\exists v \mbf{r}(\varphi)$.

     \item If $\varphi$ is of the form $\forall v \psi$, then $\mbf{r}(\varphi)$ is $\forall v \mbf{r}(\varphi)$.
    \end{enumerate}
  }

  In particular, each sentence $\varphi$ is sent to a $\msf{Prop}$ $\mbf{r}(\varphi)$.


  \definition{
    \label{def-satisfiability}
    Let $A$ be an $\mc{L}$-structure, and let $\varphi$ be a sentence. We say that $A$ \tbf{satisfies} $\varphi$, written
    $$
A \models \varphi,
$$
if $\entails \mbf{r}(\varphi)$.
}

\definition{
  \label{def-model}
Let $T$ be an $\mc{L}$-theory, and let $A$ be an $\mc{L}$-structure. We say that $A$ is a \tbf{model} of $T$ if for every sentence $\varphi : T$, $A \models \varphi$.
}

\example{
(Line graph)  The \tbf{language of graphs} $\mc{L}_{\msf{Graph}}$ comprises a single $2$-ary relation symbol $E$.

  The \tbf{theory of graphs} $\msf{Graph}$ comprises the sentence $\forall x \forall y \left(E(x,y) \leftrightarrow E(y,x)\right)$.

  The natural numbers $\N$ can be viewed as a model of $\msf{Graph}$ as follows. We realize $E$ as the set
  $$
(y = \opn{succ} x) \lor (x = \opn{succ} y) : \N \to \N  \to \msf{Prop}
$$
which is clearly symmetric.
}

\example{
  Let $\Mod(\msf{Graph})$ be the collection of graphs.\footnote{Warning: this is ``large'', so lives in the next universe up: one can interpret a trivial edge relation on \emph{every} type in the current universe.} A \tbf{graph property} is a map $P : \Mod(\msf{Graph}) \to \Prop$ such that whenever $G \simeq G'$, $P(G) \leftrightarrow P(G')$. We say that $G$ \emph{satisfies} $P$ if $P(g) \leftrightarrow \true$. A graph property is additionally said to be \emph{monotone} if whenever $G \subseteq G'$ is a subgraph, then $P(G') \rightarrow P(G)$.

  For example, the property of being a complete graph is not monotone, while the property of being cycle-free is.

  The \tbf{graph evasiveness conjecture} says that for every monotone graph property $P$ and every $n : \N$, one needs to ask $\binom{n}{2}$ questions of the form ``is there an edge between $v$ and $w$'' to determine if an arbitrary graph on $n$ vertices satisfies $P$.
  }

\example{\label{example-PA}
  (Peano arithmetic)

  The \tbf{language of Peano arithmetic} $\mc{L}_{\msf{PA}}$ comprises:
  \begin{enumerate}
  \item A $1$-ary constant $0$.
  \item Three function symbols $\opn{succ}, +, \times$.
  \end{enumerate}

  The \tbf{theory of Peano arithmetic} $\msf{PA}$ comprises:
  \begin{enumerate}
  \item $\forall x, s(x) \neq 0$
  \item $\forall x \forall y, (s(x) = s(y)) \to x = y$
  \item $\forall x, x + 0 = x$
  \item $\forall x \forall y, x + s(y) = s(x + y)$
  \item $\forall x, x \times 0 = 0$
  \item $\forall x \forall y, x \times S(y) = (x \times y) + x$
  \item[Schema:] For every $\mc{L}_{\msf{PA}}$-formula $\varphi(x)$ with one free variable $x$,
    $$
\medleft \varphi(0) \land \forall x (\varphi(x) \rightarrow  \varphi(\opn{succ} x) ) \medright \rightarrow \forall x \varphi(x).
    $$
  \end{enumerate}

  The \tbf{standard model} of $\msf{PA}$ is $\N$ with $0$ realized as $0 : \N$, $\opn{succ}$ realized as $\opn{succ} : \N \to \N$, $+$ realized as $+ : \N \to \N \to \N$, and $\times$ realized as $\times : \N \to \N \to \N$.
}

By recursing on the inductive type of valid sentences and replacing every rule of the propositional calculus with the corresponding deduction rule for $\msf{Prop}$, we can construct for every valid $\mc{L}$-sentence $\varphi$ a proof that $\mbf{r}(\varphi) \leftrightarrow \true.$

That is the soundness theorem. (In what follows, taking $\psi$ to be $\true$ yields the assertion in the previous paragraph.)

\theorem{\label{theorem-soundness} (Soundness theorem)
  For every $\mc{L}$-structure and any sentences $\varphi, \psi : \msf{Sentences}(\mc{L})$, $$\entails_{\mc{L}} \varphi \to \psi \hspace{4mm} \implies \hspace{4mm} \entails \mbf{r}(\varphi) \to \mbf{r}(\psi).$$
}


This happens regardless of which $\mc{L}$-structure is doing the realizing. When the $\mc{L}$-structure itself is a model of a theory $T$, then whenever $T \entails_{\mc{L}} \psi$, then since there is some sentence $\varphi : T$ such that $\entails_{\mc{L}}\varphi \to \psi$, $\msf{Prop}$'s modus ponens tells us that the model satisfies $\psi$ also.

  \example{
    For example, suppose we're working in the language of graphs expanded with two $1$-ary constants $a$ and $b$, and we know that there is some model $M$ such that $M$ satisfies the sole axiom that $E$ is symmetric. We can show
    $$
\vdash (\forall x \forall y, \mbf{r}(E)(x,y) \leftrightarrow \mbf{r}(E)(y,x)) \rightarrow \mbf{r}(E)(\mbf{r}(a), \mbf{r}(b)) \leftrightarrow \mbf{r}(E)(\mbf{r}(b), \mbf{r}(a))
$$
because we already know the antecedent and can apply $\msf{Prop}$'s $\forall$-elimination.
}

The converse of \myref{Theorem}{theorem-soundness} is false. There may be some things which are incidentally true about the model which are not universally valid.

\example{
  Working again in the language of graphs, consider a complete graph on $n$ vertices. Call this model $M$. $M$ happens to satisfy the $\mc{L}$-sentence
  $$
\medleft \forall x \forall y, E(x,y) \leftrightarrow E(y,x) \medright \rightarrow \medleft \forall x \forall y \forall z, E(x,y) \land E(y,z) \rightarrow E(x,z)\medright,
$$
but this is not a valid $\mc{L}$-sentence. (Indeed, if it were, then the soundness theorem would imply that \emph{every} graph has a transitive edge relation, which is not true.)
}

It will turn out that we can do the next best thing. If we rule out this kind of exception by requiring that $M \models \varphi$ \emph{for every $\mc{L}$-structure} $M$ (resp. every model $M$ of $T$), then it follows that $\entails_{\mc{L}} \varphi$ (resp. $T \entails_{\mc{L}} \varphi$). This is the completeness theorem.
  
  \subsection{The completeness theorem}
In this section, our goal will be to prove the \tbf{completeness theorem}:
\theorem{\label{theorem-completeness} Let $T$ be an $\mc{L}$-theory. $T$ is consistent if and only if there exists a model of $T$.}

First we will prove that if there exists a model $M$ of $T$, then $T$ is consistent.

\begin{proof}
  We will show the contrapositive: if $T$ is inconsistent, then there does not exist a model $M$ of $T$.

  Indeed, suppose that $T$ is inconsistent. Suppose there is a model $M$. Then by the soundness theorem, $M \models \false$. By definition, this means that
  $$
\entails \false,
$$
so we have shown that
$$
\entails \te{($T$ inconsistent) $\wedge$ (there exists a model $M$ of $T$) $\rightarrow \false$}
$$
which is equivalent to
$$
\entails (T \te{ not inconsistent}) \lor (T \te{ does not have a model}),
$$
which is equivalent to
$$
\entails T \te{ inconsistent } \rightarrow T \te{ does not have a model.}
$$
Taking the contrapositive, we conclude that if $T$ has a model, then $T$ is consistent.
\end{proof}

It then remains to show that if $T$ is consistent, $T$ has a model. We will first prove \myref{Theorem}{theorem-completeness} in the case where the language $\mc{L}$ of $T$ is \emph{relational}, i.e. has no function symbols. Later, we will show that to every theory $\mc{L}$-theory $T$ we can associate a relational language $\mc{L}_{\opn{rel}}$ and an $\mc{L}_{\opn{rel}}$-theory $T_{\opn{rel}}$ by replacing function symbols with their graph relations. Then we will show that if $T$ is consistent, so is $T_{\opn{rel}}$, and that every model of $T_{\opn{rel}}$ gives rise to a model of $T$, which will give the full completeness theorem.

Before proceeding, we prove a lemma, valid for any consistent theory in any language.

\lemma{Suppose $T$ is consistent. Let $\varphi$ be an $\mc{L}$-sentence. Then $T \cup \{\varphi\}$ is consistent or $T \cup \{\neg \varphi\}$ is consistent.}

\begin{proof}
  Suppose that both $T \cup \{\varphi\}$ and $T \cup \{ \neg \varphi\}$ are inconsistent. Then there exist sentences $\sigma$ and $\rho$ from $T$ such that
  $$
\entails_{\mc{L}} (\sigma \wedge \varphi) \to \false \hspace{2mm} \te{ and } \hspace{2mm} \entails_{\mc{L}} (\rho \wedge \neg \varphi) \to \false.
$$
By $\neg$-introduction, we get
$$
\entails_{\mc{L}} \neg \left(\sigma \wedge \varphi\right) \hspace{2mm} \te{ and } \hspace{2mm} \entails_{\mc{L}} \neg \left(\rho \wedge \neg \varphi\right)
$$
and by $\wedge$-introduction, we get
$$
\entails_{\mc{L}} \left(\neg(\sigma \wedge \varphi) \right) \wedge \left(\neg (\rho \wedge \neg \varphi) \right).
$$
Since the finitary de Morgan laws are tautologies in the sense of \ref{def-tautology}, it follows that
$$
\entails_{\mc{L}} \neg \left(\sigma \lor \varphi \lor \rho \lor \neg \varphi\right).
$$
Since the metatheory satisfies the law of the excluded middle, we have that the law of the excluded middle for $\mc{L}$-formulas is a tautology in the sense of \ref{def-tautology}. Therefore,
$$
\entails_{\mc{L}} \neg(\sigma \lor \rho) \Leftrightarrow \entails_{\mc{L}} \neg \sigma \land \neg \rho,
$$
so by $\wedge$-elimination,
$\entails_{\mc{L}} \neg \sigma$ and $\entails_{\mc{L}} \neg \rho$, so $T$ is inconsistent.
\end{proof}

\theorem{
\label{theorem-propositional-completeness} Suppose that $S$ is a relational theory, containing no quantifiers, and which is consistent. Then $S$ has a model.
}

\begin{proof}
  We start by choosing a well-ordering of $S$, which induces a well-ordering of the constant and relation symbols which appear in $S$. In turn, this induces a lexicographic ordering on all sentences of the form $c_i = c_j$ and $R_{\beta}(c_1, \dots, c_n)$ where $c_i, c_j$ and $R_{\beta}$ are constant and relation symbols occuring in $S$. Collect these sentences into a single well-ordered set $(F_{\alpha})$.

  Now, we inductively decide whether the $F_{\alpha}$ should be true or false consistent with $S$. We put $G_{0} \dfeq F_0$ if $S \cup \{F_0\}$ is consistent; otherwise we put $G_0 \dfeq \neg F_0$. Similarly, for $\beta > 0$ we put $G_{\beta} \dfeq F_{\beta}$ if $S \cup \{G_{\alpha} \stbar \alpha < \beta\} \cup \{F_{\beta}\}$ is consistent, and we put $G_{\beta} \dfeq \neg F_{\beta}$ otherwise.

  From the previous lemma, at each stage $\beta$ of this construction, $S_{\beta} \dfeq S \cup \{G_{\alpha} \stbar \alpha < \beta\}$ is consistent. Since any inconsistency is derivable from finitely many other sentences, the union
  $$
H \dfeq \bigcup_{\beta} S_{\beta} 
$$
is consistent.

Now, there is a natural equivalence relation on the collection $\mc{C}$ of all constant symbols which occur in $H$, given by $$ c \sim_{\mc{C}} c' \iff c = c' : H .$$ Since $\mc{C}$ is well-ordered, we may pick the least element of each $\sim_{\mc{C}}$-class, and collect them as $\mc{C}'$. We will make $\mc{C'}$ into a model of $H$. First, we realize every constant symbol $c$ as the chosen least representative of its $\sim_{\mc{C}}$-class.

For every ($n$-ary) relation symbol $R_{\beta}$, we realize $R_{\beta}$ by putting
$$
R_{\beta}^{\mc{C}} \left(c_1, \dots, c_n\right) \leftrightarrow \medleft R(c_1, \dots, c_n) : H \medright.
$$

It remains to show that $M$ is a model of $S$. Since $S$ was quantifier-free, then by the inductive definition of formulas, every sentence in $S$ is a Boolean combination of atomic sentences (precisely the $F_{\alpha}$) or their negations. Let $\varphi : S$. We can additionally rearrange $\varphi$ into a disjunctive normal form, so that
$$
\varphi \equiv \bigvee_{i \leq n} \left(\bigwedge_{j \leq m_i}L^i_j\right),
$$
where each $L^i_j$ is an atomic or negated-atomic sentence. For each disjunctand $\bigwedge_{j \leq m_i} L^i_j$, we have each of the $L^i_j$ belong to $\{F_{\alpha}\}$, so either $L^i_j$ or $\neg L^i_j$ belongs to the $\{G_{\alpha}\}$. It follows that if for every $\bigwedge_{j \leq m_i} L^i_j$, there exists some $L^i_{j}$ such that $\neg L^i_j$ is in $\{G_{\alpha}\}$, then $H \entails \neg \varphi$ is inconsistent. Therefore, there must be some disjunctand $\bigwedge_{j \leq m_i} L^i_j$ such that every $L^i_j$ is in $\{G_{\alpha}\}$.

Since $M$ was designed to satisfy the $G_{\alpha}$, the propositional calculus implies that $M \models \varphi$. Since $\varphi : S$ was arbitrary, $M \models S$.
\end{proof}

\definition{
Let us say that two $\mc{L}$-theories $T$ and $T'$ are \emph{equivalent} if every sentence of $T$ can be proved from $T'$ and every sentence of $T'$ can be proved from $T$. It is easy to see that if $T$ and $T'$ are equivalent, $T$ is consistent if and only if $T'$ is consistent.
}

\definition{
We say that a sentence $\varphi$ is in \tbf{prenex normal form} if any quantifiers occurying in $\varphi$ occur together at the beginning of $\varphi$. We say that a theory is in prenex normal form if every sentence in $T$ is in prenex normal form.
}

\lemma{
Every theory $T$ is equivalent to a theory $T'$ in prenex normal form.
  }

  \begin{proof}
    Apply the change-of-variables rule and the de Morgan rules for quantifiers to change any sentence not in the desired form into one in $T'$.
  \end{proof}
  
\theorem{\label{theorem-relational-completeness}Now suppose that $S$ is a relational theory, which possibly contains quantifiers, and is consistent. Then $S$ has a model.}
\begin{proof}
  Let $T$ be a theory whose sentences are either quantifier-free or begin with a quantifier. We expand $T$ (and the language) as follows: for every sentence in $T$ of the form $\exists x \varphi(x)$, we expand the language by a new constant symbol $c$ and adjoin to $T$ the sentence $\varphi(c)$, and for every sentence in $T$ of the form $\forall x \varphi(x)$ and every constant $c$ already occuring in $T$, we adjoin the sentence $\varphi(c)$. We call the result of this process $T^*$.

  We observe that whenever $T$ is consistent, so is $T^*$: if $T^* \entails_{\mc{L}} \false$, then there are finitely many sentences $\varphi_1, \dots, \varphi_n$ from $T^*$ such that $\entails_{\mc{L}}\left(\bigwedge_{i} \varphi_i \right) \to \false$. We regroup this conjunction according to whether or not $\varphi_i$ contains a new constant symbol or not, viz.
  $$
\entails_{\mc{L}} \left(\bigwedge_{i} \varphi_i \right) \wedge \left(\bigwedge_{j} \psi_j(c_j)\right) \to \false,
$$ where $c_j$ are the new constant symbols. Applying the generalization of constants deduction rule and the de Morgan rules, we conclude that
$$
\entails_{\mc{L}} \left(\bigwedge_{i} \varphi_i \right) \wedge \left(\exists x_j\bigwedge_{j} \psi_j(x_j)\right) \to \false 
$$
and therefore
$$
\entails_{\mc{L}} \left(\bigwedge_{i} \varphi_i \right) \wedge \left(\bigvee_{j} \neg \exists x_j \psi_j(x_j)\right).
$$
So, for some $j$, $\entails_{\mc{L}} \exists x_j \psi_j(x_j)$, but by construction $\exists x_j \psi_j(x_j) : T$ for $\psi_j(c_j)$ to be in $T^*$. Therefore, $T$ is not consistent.

Now let $S$ be any consistent theory. We put $S_0 \dfeq S$ and if $S_n$ has already been defined, we put $S_{n+1} \dfeq \left(S_n\right)^*$. Then we obtain a consistent limit theory $\ol{S} \dfeq \bigcup_{n \in \N} S_n$, and we define the model $M$ as we did in the quantifier-free case for the quantifier-free part of $\ol{S}$.
\end{proof}

\proposition{\label{prop-T-rel-is-conservative}
Let $T$ be an $\mc{L}$-theory, and let $T_{\opn{rel}}$ be the associated $\mc{L}_{\opn{rel}}$-theory obtained by replacing function symbols with their graphs. Then any model $M_{\opn{rel}} \models T_{\opn{rel}}$ can be viewed as a model $M \models T$.
}

\begin{proof}[Sketch.]
For every function symbol $f$ of $\mc{L}$, we interpret $f$ as the function specified by the graph relation $\Gamma_f$ in $\mc{L}_{\opn{rel}}$, which was axiomatized in $T_{\opn{rel}}$ to be the graph of a function. This gives an $\mc{L}$-structure $M$. Since $M \models T_{\opn{rel}}$ and every sentence of $T_{\opn{rel}}$ is either a modified version of a sentence in $T$ or asserts that a new relation is a graph of a function, $M \models T$. 
\end{proof}

\proposition{
Let $T$ be an $\mc{L}$-theory. If $T$ is consistent, then $T_{\opn{rel}}$ is consistent.
}
\begin{proof}[Sketch.]
 Suppose towards the contrapositive that $T_{\opn{rel}}$ is inconsistent. Then there is a proof from $T_{\opn{rel}}$ of $\false$. It suffices to show that replacing the graphs $\Gamma_f$ by the functions $f$ induces a deduction-preserving map from the valid $\mc{L}_{\opn{rel}}$-sentences to the valid $\mc{L}$-sentences, for then we will have a proof from $T$ of $\false$. This can be done by induction and a case-by-case analysis of the rules of deduction.
\end{proof}

\subsection{The Henkin construction}
\definition{\label{def-henkin-theory} Let $T$ be an $\mc{L}$-theory. We say that $T$ is a \tbf{Henkin theory} if, for every formula $\varphi(x)$, there is a constant $c : \msf{Const}(\mc{L})$ such that
  $T \entails_{\mc{L}} (\exists x \varphi(x)) \rightarrow \varphi(c).$}

\example{\label{fields-henkin} Let $\mc{L}_{\opn{field}}$ be the language of fields, which we define to be $\{0, 1, +, \times, (-)^{-1}\}$ (the usual language of rings augmented with an inversion operation), and let $T$ be the usual axiomatization of a field of characteristic zero. $T$ is not a Henkin theory, for there is no constant $c$ such that e.g. $c = (1 + 1)^{-1}$.}

  \example{\label{true-arithmetic-is-not-a-Henkin-theory} Let $\mc{L}_{\msf{PA}}$ be the language of Peano arithmetic (see \myref{Example}{example-PA}). Let $T$ be the collection of all $\mc{L}_{\msf{PA}}$-sentences $\psi$ such that $N \models \psi$. Then $T$ certainly contains the sentence $\exists x \forall y, x \cdot y = y$. However, $1 = \opn{succ} \hspace{1mm}0$ is not a constant in the language, but rather a term. So $T$ is not a Henkin theory.

    However, if we \emph{expand} $\mc{L}_{\msf{PA}}$ to a language $\mc{L}'$ with a constant symbol $c_n$ for every natural number $n$, and if we let $T'$ be the collection all $\mc{L}'$-sentences $\psi$ such that $\N$ (viewed in the natural way as a model of $\mc{L}'$) satisfies $\psi$, then $T'$ \emph{is} a Henkin theory.
  }

  \proposition{\label{prop-extend-henkin}
    Let $T$ be an $\mc{L}$-theory. If $T$ is consistent, then there exists a language $\mc{L}'$ extending $L$ and an $\mc{L}'$-theory $T'$ extending $T$ viewed as an $\mc{L}$'-theory, such that $T'$ is a Henkin theory.

    Furthermore, if $T$ is consistent, then $T'$ is consistent.
}

\begin{proof}
  Put $\mc{L}_0 \dfeq \mc{L}$ and $T_0 \dfeq T$. We define a chain of languages $\mc{L}_i$ and for each $i$ we define an $\mc{L}_i$-theory $T_i$ as follows: given $\mc{L}_n$ and $\mc{T}_n$, let $\mc{L}_{n+1}$ be the language obtained by adding a constant $c_{\varphi, x}$ where $\varphi$ ranges over all $\mc{L}_{n}$-formulas and $x$ ranges over the free variables of $\varphi$.

  Having defined $\mc{L}_{n+1}$, we now define $T_{n+1}$ to be
  $$
T_{n} \cup \{\exists x \varphi(x) \rightarrow \varphi(c_{\varphi,x})\}_{\varphi, x}
$$
where above we have adjoined a sentence saying that the newly-adjoined constant $c_{\varphi,x}$ behaves as expected.

We put $$T' \dfeq \displaystyle \bigcup_{n \opn{:} \N} T_n.$$ By construction, $T'$ is a Henkin theory.

It remains to show that if $T$ is consistent, so is $T'$. If $T \entails_{\mc{L}} \psi$, then from the finiteness of proofs, we must have that $T_n \entails_{\mc{L}}$ for some $n$. So, to show $T'$ is consistent, it suffices to show that for each $n$, $T_n$ is consistent.

We induct on $n$. The base case $T = T_0$ is by assumption. For the induction step, we must show that if $T_n$ is consistent, then $T_{n+1}$ is consistent.

Suppose towards the contrapositive that $T_{n+1}$ is inconsistent. Since $T_{n+1}$ is obtained by adjoining formulas of the form $\exists x \varphi(x) \rightarrow \varphi(c)$, there must be finitely many such formulas $\psi_1, \dots, \psi_m : T_{n+1} \backslash T_n$ of this form, along with finitely many formulas $\rho_1, \dots, \rho_n$ from $T_n$, such that
$$
\entails_{\mc{L}} \rho_1 \wedge \dots \wedge \rho_n \wedge \psi_1 \wedge \dots \wedge \psi_m \to \false.
$$
By material implication, we get that
$$
\entails_{\mc{L}} \rho_1 \wedge \dots \wedge \rho_n \wedge \psi_1 \wedge \dots \wedge \psi_{m-1} \to \neg \psi_m,
$$
which is equivalent to
$$
\entails_{\mc{L}} \rho_1 \wedge \dots \wedge \rho_n \wedge \psi_1 \wedge \dots \wedge \psi_{m-1} \to \neg (\exists x \varphi_m(x) \rightarrow \varphi_m(c_m)),
$$
which is equivalent to
$$
\entails_{\mc{L}} \rho_1 \wedge \dots \wedge \rho_n \wedge \psi_1 \wedge \dots \wedge \psi_{m-1} \to (\exists x \varphi_m(x)) \wedge \neg \varphi_m(c_m)),
$$
and since
$$
\entails_{\mc{L}} (\exists x \varphi_m(x)) \wedge \neg \varphi_m(c_m)) \to \false,
$$
we conclude that $$\rho_1 \wedge \dots \wedge \rho_n \wedge \psi_1 \wedge \dots \wedge \psi_{m-1}$$ is inconsistent. Continuing this way, we eliminate all the $\psi_i$ and conclude that $\rho_1 \wedge \dots \wedge \rho_n$ is inconsistent, and therefore that $T$ is inconsistent, which gives the contrapositive of the induction hypothesis.
\end{proof}

\newcommand{\term}{\opn{term}}
\definition{
  \label{def-term-model}
  To any Henkin $\mc{L}$-theory $T$, we can associate a canonical structure (a ``term model'') $\opn{term}(T)$ built from the closed terms (i.e. those not containing any variables).

  First, we take the collection $A$ of all closed $\mc{L}$-terms. We define a relation $E : A \to A \to \Prop$, with the convention that $\entails E \hspace{2mm} a_1 \hspace{2mm}  a_2 \leftrightarrow \true$ if and only if $T \entails_{\mc{L}} a_1 = a_2$. By the rules about equality that we have stipulated as part of the predicate calculus, $E$ is an equivalence relation.

  We put $\wt{A} \dfeq A/E$. This will be the underlying type of the model.

  For a constant $c : \msf{Const}(\mc{L})$, we put $c^{\wt{A}} \dfeq c/E$ ($c$ belongs to $\mc{L}_0$, and so is a closed term of $\mc{L}'$).

  For a relation symbol $R : \msf{Rel}(\mc{L})$, we define $R^{\wt{A}} : \wt{A}^{\arity(R)} \to \Prop$ by $R^{\wt{A}}\left(a_1/E, \dots, a_n/E\right) \leftrightarrow T' \entails_{\mc{L}} R(a_1, \dots, a_n)$.

  For a function symbol $f : \msf{Funct}(\mc{L})$, we define $f^{\wt{A}} : \wt{A}^{\arity(f)} \to \wt{A}$ by
  $$
\lambda a_1/E \hspace{2mm} \dots \hspace{2mm} a_n/E, f(a_1, \dots, a_n)/E.
$$
This completes the definition of $\term(T)$.
}
By the soundness theorem, if $T$ is inconsistent, then $\term(T)$ cannot be a model of $T$. But the inverse is true.

\proposition{
Let $T$ be a Henkin $\mc{L}$-theory. If $T$ is consistent, then $\term(T)$ is a model of $T$.
}
\begin{proof}
  We will show that for every $\psi : \msf{Sentences}(\mc{L})$,
$$
T \entails \psi \leftrightarrow \term(T) \models \psi.
$$
We will do this by a structural induction on formulas. In the base case, we have atomic sentences.

\begin{itemize}
\item If $T \entails_{\mc{L}} \psi$ and $\psi$ is of the form $a_1 = a_2$ where $a_1$ and $a_2$ are closed terms, then since $T \entails_{\mc{L}} a_1 = a_2$, then $\entails a_1^{\wt{A}} = a_2^{\wt{A}}$ (in $\wt{A}$), so $\term(T) \models \psi$.

  Conversely, if $\term(T) \models \psi$, then $\entails a_1^{\wt{A}} = a_2^{\wt{A}}$, so by definition of the equivalence relation we used to define $\wt{A}$, $T \entails_{\mc{L}} a_1 = a_2$.

\item If $T \entails_{\mc{L}} \psi$ and $\psi$ is of the form $R(a_1, \dots, a_n)$ where $R$ is a relation symbol and $a_1, \dots, a_n$ are closed terms, then since $T \entails_{\mc{L}} R(a_1, \dots, a_n)$, we have that $\entails R^{\wt{A}}(a_1^{\wt{A}}, \dots, a_n^{\wt{A}})$.

  Conversely, if $\term(T) \models \psi$, then $\entails R^{\wt{A}}(a_1^{\wt{A}}, \dots, a_n^{\wt{A}})$, so by definition of how we interpreted $\mc{L}$ onto $\wt{A}$, $T \entails_{\mc{L}} R(a_1, \dots, a_n)$.

\item If $T \entails_{\mc{L}} \psi$ and $\psi$ is of the form $\varphi_1 \wedge \varphi_2$, then by $\wedge$-elimination in $\msf{Sentences}(\mc{L})$, $$\entails (T \entails_{\mc{L}} \psi) \rightarrow (T \entails_{\mc{L}} \varphi_1) \wedge (T entails_{\mc{L}} \varphi_2).$$ By the induction hypothesis, $\term(T) \models \varphi_1$ and $\term(T) \models \varphi_2$, so by $\wedge$-introduction in $\Prop$, $\term(T) \models \varphi_1 \wedge \varphi_2$.

  Conversely, if $\term(T) \models \varphi_1 \wedge \varphi_2$, then by $\wedge$-elimination in $\Prop$, $\term(T) \models \varphi_1$ and $\term(T) \models \varphi_2$. By the induction hypothesis, $T \entails_{\mc{L}} \varphi_1$ and $T \entails_{\mc{L}} \varphi_2$, so by $\wedge$-introduction in $\msf{Sentences}(\mc{L})$, $T \entails_{\mc{L}} \varphi_1 \wedge \varphi_2$.

\item Suppose $T \entails_{\mc{L}} \psi$ and $\psi$ is of the form $\neg \varphi$. The induction hypothesis says that $T \entails_{\mc{L}} \varphi$ if and only if $\term(T) \models \varphi$. Since $T$ is consistent, $T \not \entails_{\mc{L}} \varphi$. Therefore, by the induction hypothesis, $\term(T) \not \models \varphi$. Since
  $$
\term(T) \models \varphi \leftrightarrow \entails \mbf{r}(\varphi),
$$
we have that
$$
\entails \neg \mbf{r}(\varphi),
$$
but $\neg \mbf{r}(\varphi) \leftrightarrow \mbf{r}(\neg \varphi)$. We conclude that $M \models \neg \varphi$.

We omit the cases for $\wedge$ and $\rightarrow$, which are entirely analogous.

We conclude that whenever $\psi$ is quantifier-free, $T \entails_{\mc{L}} \psi$ if and only if $\term(T) \models \psi$.

To complete the proof, we must take care of quantifiers.

\item Suppose that $T \entails_{\mc{L}} \exists x \varphi(x)$, where $\varphi(x)$ satisfies the induction hypothesis that if we substitute a closed term $c$ for $x$, $\varphi(c)$ is a sentence such that $T \entails_{\mc{L}} \varphi(c)$ if and only if $\term(T) \models \varphi(c)$.

  Then, since $T$ is a Henkin theory, there exists some $c$ such that
  $$
T \entails_{\mc{L}} \varphi(c).
$$
By the induction hypothesis, we have that
$$
\term(T) \models \varphi(c),
$$
and therefore by $\exists$-introduction in $\Prop$, we conclude that
$$
\term(T) \models \exists x \varphi(x).
$$

Conversely, suppose that $\term(T) \models \exists x \varphi(x)$. By $\exists$-elimination in $\Prop$, there exists some $a/E : \wt{A}$ such that $\entails \mbf{r}(\varphi)(a/E)$, which is equivalent to $\term(T) \models \varphi(a)$. By the induction hypothesis, $T \entails_{\mc{L}} \varphi(a)$, and by $\exists$-introduction in $\msf{Sentences}(\mc{L})$, $T \entails_{\mc{L}} \exists x \varphi(x)$.

\item Similarly, suppose that $T \entails_{\mc{L}} \forall x \varphi(x)$, where $\varphi(x)$ satisfies the induction hypothesis that if we substitute a closed term $c$ for $x$, $\varphi(c)$ is a sentence such that $T \entails_{\mc{L}} \varphi(c)$ if and only if $\term(T) \models \varphi(c)$.

  Then by $\forall$-elimination in $\msf{Sentences}(\mc{L})$, we have that for every constant $c : \msf{Const}(\mc{L})$, $T \entails_{\mc{L}} \varphi(c)$. By the induction hypothesis, $\term(T) \models \varphi(c)$. Since the interpretations of $c$ exhaust $\term(T)$, we conclude by $\forall$-introduction in $\Prop$ that $\term(T) \models \forall x \varphi(x)$.

  Conversely, suppose that $\term(T) \models \forall x \varphi(x)$. By $\forall$-elimination in $\Prop$, for every $a/E \in \wt{A}$, $\entails \mbf{r}(\varphi)(a/E)$, which is equivalent to $\term(T) \models \varphi(a)$. By the induction hypothesis, for every $c : \msf{Const}(\mc{L})$, $T \entails_{\mc{L}} \varphi(c)$.

  Since $T$ is consistent, for every $c$, $T$ does not prove $\neg \varphi(c)$, so $\term(T) \models \neg \varphi(c) \to \false$, and therefore $T \entails \neg \varphi(c) \to \false$. Specializing to a $c$ which does not occur in $\varphi$, we get from $\forall$-introduction \ref{forall-introduction} in $\msf{Sentences}(\mc{L})$ that $T \entails_{\mc{L}} \exists x \neg \varphi(x) \to \false$. By the de Morgan laws, $T \entails_{\mc{L}} \forall x \neg \neg \varphi(x)$. Since we are assuming double-negation elimination is a propositional tautology, we conclude that $T \entails_{\mc{L}} \forall x \varphi(x)$.
\end{itemize}

\end{proof}

\subsection{The L\"owenheim-Skolem theorem}

\section{$\msf{ZFC}$}

\section{Generic sets: Cohen's original proof}


\section{Boolean-valued models}


\section{Sheaves and filterquotients}


\end{document}